{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c577f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is a Naïve Bayes Classifier?\n",
    "\n",
    "1. It is Supervised Machine Learning Algorithm\n",
    "2. We can use it to solve the classification Problems\n",
    "3. Based on Bayes Theorem\n",
    "4. Naive term is having an assumption\n",
    "5. Naive  >> It assumes that, Features are mutually independent(Input)\n",
    "6. Naive bayes is also called as Probabilistic algorithm\n",
    "7. We do use it mostly on Text classification, That means we can consider NLP Data."
    "8 trial and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What are the different types of Naive Bayes classifiers?\n",
    "\n",
    "1. Multinomial NB >> TF-IDF\n",
    "2. Gaussian NB    >> Continuous\n",
    "3. Bernoulis NB   >> Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffe65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Why Naive Bayes is called Naive?\n",
    "\n",
    "Naive term is having an assumption\n",
    "It assumes that, Features are mutually independent(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e92b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Can you choose a classifier based on the size of the training set?\n",
    "\n",
    "Yes we can choose classifier based on training data set ,\n",
    "If the training set is small, high bias / low variance models (e.g. Naive Bayes) tend to perform better because they are \n",
    "less likely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Explain Bayes Theorem in detail?\n",
    "\n",
    "In statistics and probability theory, the Bayes’ theorem (also known as the Bayes’ rule) is a mathematical formula used to \n",
    "determine the conditional probability of events. Essentially, the Bayes’ theorem describes the probability of an event based \n",
    "on prior knowledge of the conditions that might be relevant to the event.\n",
    "\n",
    "Posterior Probalility  = (Likelihood  * Prior)/(Marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is the formula given by the Bayes theorem?\n",
    "\n",
    "P(A/B) =P(B/A).P(A) /P(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b347475",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What is posterior probability and prior probability in Naïve Bayes?\n",
    "\n",
    "1.The probability of happening The event early or prior or before called prior probability.\n",
    "\n",
    "2.The Probability of happening the event later to the prior called posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Define likelihood and evidence in Naive Bayes?\n",
    "\n",
    "we are trying to find probability of event A, given the event B is true.\n",
    "\n",
    "Evidence is the event that already have happend.\n",
    "\n",
    "Likelihood is The chance or probability that something will happen i.e. probability very little likelihood of happening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Define Bayes theorem in terms of prior, evidence, and likelihood.\n",
    "\n",
    "Bayes' Theorem states that the conditional probability of an event, based on the occurrence of another event, is equal to the \n",
    "likelihood of the second event given the first event multiplied by the probability of the first event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. How does the Naive Bayes classifier work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. While calculating the probability of a given situation, what error can we run into in Naïve\n",
    "Bayes and how can we solve it?\n",
    "\n",
    "Errors:\n",
    "1.The probability an instance is misclassified by a classifier that knows the true class probabilities given the predictors.\n",
    "2.Unseen observations can lead to 0 probabilities.\n",
    "\n",
    "Solution:\n",
    "    \n",
    "1.Convert the given dataset into frequency tables. Generate Likelihood table by\n",
    "finding the probabilities of given features. Now, use Bayes theorem to calculate the posterior probability.\n",
    "\n",
    "2.Laplace smoothing is a smoothing technique that helps tackle the problem of zero\n",
    "probability in the Naïve Bayes machine learning algorithm. Using higher alpha values will push the likelihood towards a value\n",
    "of 0.5, i.e., the probability of a word equal to 0.5 for both the positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. How would you use Naive Bayes classifier for categorical features? What if some features are numerical?\n",
    "\n",
    "We can use naïve bayes classifier for categorical variables using one-hot encoding.\n",
    "If we have n categories then we create n-1 dummy variables or features and add to our\n",
    "data.\n",
    "\n",
    "If the particular category is associated with a row then we assign it as 1 otherwise 0.\n",
    "If we have some numerical features we can discretize numeric values into few categories.\n",
    "\n",
    "For example\n",
    "we can categorize marks of students in a class as low, medium or high.\n",
    "\n",
    "Other method we can use for this is probability density function where we assume the probability distribution of attribute\n",
    "follows a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. What's the difference between Generative Classifiers and Discriminative Classifiers?\n",
    "\n",
    "Name some examples of each one\n",
    "\n",
    "Generative model is based on the joint probability, p( x, y), of the inputs x and the label y, and make their predictions \n",
    "by using Bayes rules to calculate p(y | x), and then picking the most likely label y.e.g Naive Bays Classifier.\n",
    "\n",
    "A Generative model assumes that all the features are conditionally independent\n",
    "Discriminative classifiers model the posterior p(y | x) directly, or learn a direct map from inputs x to the class labels .\n",
    "\n",
    "while discriminative model does not assume anything related to the independence of\n",
    "features.\n",
    "e.g.Logistic Regression is a Discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5303f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. Is Naive Bayes a discriminative classifier or generative classifier?\n",
    "\n",
    "Naive bayes is a Generative model whereas Logistic Regression is a Discriminative model.\n",
    "\n",
    "Generative model is based on the joint probability, p( x, y), of the inputs x and the label y, and make their predictions by \n",
    "using Bayes rules to calculate p(y | x), and then picking the most likely label y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. Whether Feature Scaling is required?\n",
    "\n",
    "No reqired feature scaling .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "16. Impact of outliers on NB Classifier?\n",
    "\n",
    "Unseen observations can lead to 0 probabilities.\n",
    "For example, Bernoulli Naive Bayes applied to word features will always produce 0 probabilities\n",
    "when it encounters a word that wasnt seen in the training data.\n",
    "Outliers in this sense can be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "17. What is the Bernoulli distribution in Naïve Bayes?\n",
    "\n",
    "Bernoulli distribution is a discrete probability distribution where the Bernoulli\n",
    "random variable\n",
    "can have only 0 or 1 as the outcome. p is the probability of success and 1 - p is the\n",
    "probability\n",
    "of failure. The mean of a Bernoulli distribution is E[X] = p and the variance, Var[X]\n",
    "= p(1-p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36487fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "18. What are the advantages of the Naive Bayes Algorithm?\n",
    "\n",
    "1. Can Handle high Dimentional data\n",
    "2. Perform well on the small datasets\n",
    "3. Hyperparameters are not required in Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f40c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. What are the disadvantages of the Naive Bayes Algorithm?\n",
    "\n",
    "1. We need to follow Independence Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "20. What are the applications of Naive Bayes.\n",
    "\n",
    "1.spam filtration\n",
    "2.Sentimental analysis\n",
    "3.classifying articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4dcf33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

